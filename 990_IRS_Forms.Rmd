---
title: 990 Database Information Collection
author: Christopher Carbonaro
date: June 5, 2019
output: html_document
---

```{r, include = F, cache = T, eval = T}
require(pacman)
p_load(tidyverse, xml2, pdftools) 
```

# Background on the 990s

All of the 990 forms available through Amazon Web Services (AWS) can be found through [this HTTPS endpoint](https://s3.amazonaws.com/irs-form-990). Each form is located at a URI which is a combination of  the endpoint (https://s3.amazonaws.com/irs-form-990) and an appended unique identifier. These identifiers can be found in the IRS's indexes of the 990s. The final form of the URI should be `https://s3.amazonaws.com/irs-form-990/"Form_Identifier_Here"_public.xml` e.g. `https://s3.amazonaws.com/irs-form-990/201541349349307794_public.xml`. The indexes can be found as CSV files by appending a string of the form `index_year.csv` to the endpoint. For example, the index of 2018 filings can be found at [https://s3.amazonaws.com/irs-form-990/index_2018.csv](https://s3.amazonaws.com/irs-form-990/index_2018.csv). The indexes may also be accessible [here](http://irs-990-explorer.chrisgherbert.com/).
 
I am not the first person who has done work with these forms but making custom datasets is usually locked behind a paywall (or the database is out of date). The following code let's us take that information from AWS and turn it into a useable relational database.

# Collecting the Information

However, there is a database which provides an index of every unique IRS E-File identifier. I will be using this to access the HTTPS endpoints in batches.


```{r, include = F, cache = T, eval = T}
# Note that when reading the dataset, the document identifier variable must be read as a string.
# If read as integers, the values are too large for R to parse, resulting in inaccurate values.
Database990 <- read_csv(
  
  "C:/Users/clcar/Dropbox/Jobs and Internship Applications/Bashpole Software/Datasets - Temporary/Open990_Governance_Snack_Set_Public_2019-01-15.csv",
  col_types = cols(irs_efile_id = col_character())
  
  )


Database990 <- Database990 %>%
  group_by(name_org, ein, tax_yr) %>%
  arrange(name_org, desc(tax_yr))
```

```{r, echo = F}
head(Database990, 25)
```

The database above includes an index of every 990 filed with the IRS (with a few exceptions which can be read about )

These functions should allow for automated collection of the data. This is done by either accessing the 990's XML file or by webscraping.

```{r, include = T, eval = T}

# Aggregating XML Datasets

## This function currently creates a URI from an IRS EFile ID, prints the corresponding HTML endpoint, and reads the XML file located at that endpoint. It currently functions as an assignment operator e.g. test <- getIRS990(IRS_Efile_ID) where test is the file in XML format.

## This is the building block for a bigger function. We can either make this more robust or write other functions with it.

getIRS990 <- function(IRS_Efile_ID){

  
   URI <- str_c("https://s3.amazonaws.com/irs-form-990/",
         IRS_Efile_ID,
         "_public.xml")
   
   print(URI)
   
   read_xml(URI)
}


## Testing how long it will take to collect XML forms
benchmarkIRSRet <- function(n){
  
  indicies <- runif(n,
                  min = 1,
                  max = nrow(Database990))
  
  IDs <- Database990$irs_efile_id[indicies]
  
  start_time <- Sys.time()
  
  for(ID in IDs){
    
    print(str_c(
      "Doc ID: ",
      ID))
    
    getIRS990(ID)
    
    print(Sys.time() - start_time)
  }
}



# Getting all Field Names

## Reading a random 990 to help organize the data
test <- getIRS990(
  
  Database990$irs_efile_id[runif(1, min = 1, max = nrow(Database990))]
  
    ) %>%
  xml_ns_strip()


## Collecting all paths to fields in the base 990 Form
base_990_paths <- xml_path(xml_children(xml_find_all(xml_ns_strip(test), "//Return/ReturnData/IRS990")))
base_990_paths_noNested <- base_990_paths %>%
  map(xml_find_first, x = test) %>%
  discard(function(x){xml_length(x) > 0})


base_990_paths_nested <- map(base_990_paths, 
                             xml_find_first,
                             x = test) %>%
  keep(function(x){xml_length(x) > 0}) %>%
  map(xml_path) %>%
  map(xml_find_first, x = test) %>%
  map(xml_children)


######## Collecting the Data into a Data Frame ########

base_noNest_to_dataframe <- function(x){
  
  names <- map_chr(x, xml_name)
  values <- map_chr(x, xml_text)
  
  tibble(key = names,
         val = values)
  
}

## Using the NonProfit Governance Cheatsheet to name the variables

### (This code was used for parsing the pdf to make a useable table. I fixed a few parsing errors by hand in excel. The actual table is loaded below)
### var_names_pdf <- pdf_text("C:/Users/clcar/Dropbox/Jobs and Internship Applications/Bashpole Software/Datasets - Temporary/VariableGuide_GovernanceSnackSet_2019-01-15.pdf") %>%
###   str_remove_all("Nonprofit Governance/Management\\r\\n") %>%
###   str_remove_all("Snack-sized Dataset\\r\\n") %>%
###   str_remove_all("Variable Guide\\r\\n") %>%
###   str_remove_all("This is a guide to a dataset that is under a license allowing you to share data \\(for non-commercial use\\), so long as attribution is given\\.\\r\\n") %>%
###   str_remove_all("Please attribute the dataset to Open990\\.com\\.\\r\\n") %>%
###   str_remove_all("Continued\\…\\r\\n") %>%
###   str_remove_all("Open990 Governance/Management Snack Set \\(rev\\. 2019-01-15\\)\\r\\n") %>%
###   str_remove_all("Copyright \\(c\\) 2019 by 990 Consulting, LLC\\r\\n") %>%
###   str_remove_all("Questions\\? Comments\\? We’d love to hear from you\\.\\r\\ninquiries@open990\\.com\\r\\n") %>%
###   str_replace_all(" {2,}", "\t") %>%
###   str_replace("^\\t", "") %>%
###   str_c() %>%
###   read_tsv() %>%
###   write_csv("C:/Users/clcar/Dropbox/Jobs and Internship Applications/Bashpole Software/Datasets - Temporary/Variable Names Shortcut.csv")

var_names_shortcut <- read_csv("C:/Users/clcar/Dropbox/Jobs and Internship Applications/Bashpole Software/Datasets - Temporary/Variable Names Shortcut.csv")
var_names_shortcut$`Data Type` <- as_factor(var_names_shortcut$`Data Type`)

### Getting rid of the extra document data
  

## IN PROGRESS
build990Database <- function(){
  getIRS990(IRS)
}

```

# Analyzing the Data

## The Typical Nonprofit

The following graphs and tables help give some insight into what a typical non-profit's financial situation looks like.

```{r, include=T, echo=F, eval=T}

# Discarding all variables which do not deal with finance
currency_empir <- filter(var_names_shortcut,
                         `Data Type` == "currency") %>%
  pull(`Variable Name`) %>%
  select(Database990,
         .)

ungroup(currency_empir) %>% 
  summarize_all(list(
    
    ~median(., na.rm = TRUE),
    ~sd(., na.rm = TRUE)
    
    )) %>%
  
  t()

```

